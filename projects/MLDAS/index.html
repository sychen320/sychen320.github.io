<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Bridging LiDAR Gaps: A Multi-LiDARs Domain Adaptation Dataset for 3D Semantic Segmentation">
  <meta name="keywords" content="MLDAS, 3D Domain Adaptation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Bridging LiDAR Gaps: A Multi-LiDARs Domain Adaptation Dataset for 3D Semantic Segmentation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Bridging LiDAR Gaps: A Multi-LiDARs Domain Adaptation Dataset for 3D Semantic Segmentation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Shaoyang Chen</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="">Bochun Yang</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://yan-xia.github.io/">Yan Xia</a><sup>2,3&dagger;</sup>,</span>
            <span class="author-block">
              <a href="">Ming Cheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Siqi Shen</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Cheng Wang</a><sup>1&dagger;</sup>,</span>
           
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>XMU</span>
            <span class="author-block"><sup>2</sup>TUM</span>
            <span class="author-block"><sup>3</sup>MCML</span>
          </div>

          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <img src="static/images/ijcai2024.png" alt="ijcai icon" width="180" height="40">
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Camera-ready Paper</span>
                </a>
              </span>

              <!-- arXiv Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="#overview_video"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->

              <!-- Supp Link. -->
              <span class="link-block">
                <a href="static/pdfs/supp.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supp</span>
                </a>
              </span>
              
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We focus on the domain adaptation problem for 3D semantic segmentation, addressing the challenge of data variability in point clouds collected by different LiDARs. 
            Existing benchmarks often mix different types of datasets, which blurs and complicates segmentation evaluations. Here, we introduce a <strong>M</strong>ulti-<strong>L</strong>iDAR <strong>D</strong>omain <strong>A</strong>daptation <strong>S</strong>egmentation (<strong>MLDAS</strong>) dataset, 
            which contains point-wise semantic annotated point clouds captured simultaneously by a 128-beam LiDAR, a 64-beam LiDAR, a 32-beam LiDAR. We select 31,875 scans from 2 representative scenarios: campus and urban street. 
            Furthermore, we evaluate the current 3D segmentation unsupervised domain adaptation methods on the proposed dataset and propose <strong>H</strong>ierarchical <strong>S</strong>egmentation Network with <strong>S</strong>patial <strong>C</strong>onsistency (<strong>HSSC</strong>) as a novel knowledge transfer method to mitigate the domain gap significantly using spatial-temporal consistency constraints. 
            Extensive experiments show that HSSC greatly improves the state-of-the-art cross-domain semantic segmentation methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

<div align="center" style="margin-top:80px;" style="margin-bottom:120px;">
<img style='height: auto; width: 75%; object-fit: contain' src="static/images/teaser_v10.png" alt="teaser_image">
</div>  
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Download. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Download</h2>
        <div class="content has-text-justified">
          <p>
            Please send an e-mail to <a href="mailto:sychan@stu.xmu.edu.cn">sychan@stu.xmu.edu.cn</a>, including contact details (title, full name, organization, and country) and the purpose for downloading the dataset. By sending the e-mail you accept the following <a href="static/license.html">License</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Download. -->

<section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{ijcai2024p72,
          title     = {Bridging LiDAR Gaps: A Multi-LiDARs Domain Adaptation Dataset for 3D Semantic Segmentation},
          author    = {Chen, Shaoyang and Yang, Bochun and Xia, Yan and Cheng, Ming and Shen, Siqi and Wang, Cheng},
          booktitle = {Proceedings of the Thirty-Third International Joint Conference on
                       Artificial Intelligence, {IJCAI-24}},
          publisher = {International Joint Conferences on Artificial Intelligence Organization},
          editor    = {Kate Larson},
          pages     = {650--658},
          year      = {2024},
          month     = {8},
          note      = {Main Track},
          doi       = {10.24963/ijcai.2024/72},
          url       = {https://doi.org/10.24963/ijcai.2024/72},
        }
    </code></pre>
      </div>
    </section>  





<footer class="footer">
  <div align="center" class="container">
    <div class="columns is-centered">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website is borrowed from <a href="https://github.com/3d-moments/3d-moments.github.io">3D Moments website</a>.
          </p>
          </div>
      </div>
    </div>
</footer>


</body>
</html>
